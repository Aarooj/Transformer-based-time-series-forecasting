{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a41db2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from keras.models import load_model\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# # Timestamp helper\n",
    "# def timestamp(): return time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# # Parameters for inference\n",
    "# original_samples = 20000\n",
    "# seq_length = 20\n",
    "# original_steps_to_pred = 12000\n",
    "# batch_size = 32\n",
    "# molecules = 2\n",
    "# species = '2_22'\n",
    "# horizons = np.array([1,5,10,20])\n",
    "# downsample_factor = 1\n",
    "\n",
    "# # üî• NEW: Interval reporting configuration\n",
    "# REPORT_INTERVAL = 500  # Report MAPE every 500 steps\n",
    "# MILESTONE_INTERVALS = [1000, 2500, 5000, 10000, 25000]  # Special milestone reports\n",
    "\n",
    "# samples = original_samples\n",
    "# steps_to_pred = original_steps_to_pred\n",
    "\n",
    "# print(f\"[{timestamp()}] üìä Original samples: {original_samples}, Using: {samples}\")\n",
    "# print(f\"[{timestamp()}] üìä Steps to predict: {steps_to_pred}\")\n",
    "# print(f\"[{timestamp()}] üìä Reporting MAPE every {REPORT_INTERVAL} steps\")\n",
    "\n",
    "# # Load the data\n",
    "# data = np.load('%s_data.npy' % species)\n",
    "# print(f\"[{timestamp()}] üìÅ Loaded data with shape: {data.shape}\")\n",
    "\n",
    "# data = data[:samples, :]\n",
    "# print(f\"[{timestamp()}] üìÅ Trimmed data shape: {data.shape}\")\n",
    "\n",
    "# # Verify binary flags\n",
    "# binary_flags = data[:, 6]\n",
    "# ones_indices = np.where(binary_flags == 1)[0]\n",
    "# print(f\"[{timestamp()}] ‚ö° Found {len(ones_indices)} instances of 1 in binary flag\")\n",
    "# if len(ones_indices) > 0:\n",
    "#     print(f\"First 10 indices with 1: {ones_indices[:10]}\")\n",
    "\n",
    "# # Prepare test data\n",
    "# test_data = data[-steps_to_pred - seq_length:, :]\n",
    "# print(f\"[{timestamp()}] üß™ Test data shape: {test_data.shape}\")\n",
    "\n",
    "# # Load the model\n",
    "# model = load_model('transformer_model_384_%s.h5' % species)\n",
    "# print(f\"[{timestamp()}] ‚úÖ Loaded model\")\n",
    "# print(f\"Model input shape: {model.input_shape}\")\n",
    "# print(f\"Model output shape: {model.output_shape}\")\n",
    "\n",
    "# # Helper functions\n",
    "# def create_initial_test_sequence(test_data, seq_length, step_index=0):\n",
    "#     sequence = test_data[step_index:step_index + seq_length, :]\n",
    "#     return np.expand_dims(sequence, axis=0)\n",
    "\n",
    "# def get_ground_truth(test_data, seq_length, step_index):\n",
    "#     truth = test_data[step_index + seq_length, :6]\n",
    "#     return np.expand_dims(truth, axis=0)\n",
    "\n",
    "# # üî• NEW: Function to calculate and display interval statistics\n",
    "# def report_interval_stats(performance, current_step, interval_size, mode, start_time):\n",
    "#     \"\"\"Report MAPE statistics for the current interval and overall progress\"\"\"\n",
    "    \n",
    "#     # Get valid performance data up to current step\n",
    "#     valid_perf = performance[:current_step+1][performance[:current_step+1, 0] >= 0, 0]\n",
    "    \n",
    "#     if len(valid_perf) == 0:\n",
    "#         print(f\"[{timestamp()}] Step {current_step+1:5d}: No valid predictions yet\")\n",
    "#         return\n",
    "    \n",
    "#     # Overall statistics\n",
    "#     overall_avg = np.mean(valid_perf)\n",
    "#     overall_std = np.std(valid_perf)\n",
    "#     overall_median = np.median(valid_perf)\n",
    "    \n",
    "#     # Interval statistics (last 'interval_size' valid predictions)\n",
    "#     interval_data = valid_perf[-interval_size:] if len(valid_perf) >= interval_size else valid_perf\n",
    "#     interval_avg = np.mean(interval_data)\n",
    "#     interval_std = np.std(interval_data)\n",
    "    \n",
    "#     # Calculate speed and ETA\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     steps_per_second = (current_step + 1) / elapsed_time if elapsed_time > 0 else 0\n",
    "#     remaining_steps = steps_to_pred - (current_step + 1)\n",
    "#     eta_seconds = remaining_steps / steps_per_second if steps_per_second > 0 else 0\n",
    "#     eta_minutes = eta_seconds / 60\n",
    "    \n",
    "#     # Format ETA\n",
    "#     if eta_minutes > 60:\n",
    "#         eta_str = f\"ETA: {eta_minutes/60:.1f}h\"\n",
    "#     else:\n",
    "#         eta_str = f\"ETA: {eta_minutes:.1f}min\"\n",
    "    \n",
    "#     # Print comprehensive report\n",
    "#     print(f\"[{timestamp()}] Step {current_step+1:5d}/{steps_to_pred} | Mode: {mode:13s}\")\n",
    "#     print(f\"    üìä Overall MAPE:  {overall_avg:.4f} ¬± {overall_std:.4f} | Median: {overall_median:.4f}\")\n",
    "#     print(f\"    üìà Last {len(interval_data):3d} MAPE: {interval_avg:.4f} ¬± {interval_std:.4f}\")\n",
    "#     print(f\"    ‚ö° Speed: {steps_per_second:.1f}/s | Valid: {len(valid_perf):5d}/{current_step+1} | {eta_str}\")\n",
    "\n",
    "# # üî• NEW: Function for milestone reporting\n",
    "# def report_milestone(performance, current_step, milestone_windows=[100, 500, 1000]):\n",
    "#     \"\"\"Report MAPE for different time windows\"\"\"\n",
    "    \n",
    "#     valid_perf = performance[:current_step+1][performance[:current_step+1, 0] >= 0, 0]\n",
    "    \n",
    "#     if len(valid_perf) < 50:  # Need minimum data for meaningful statistics\n",
    "#         return\n",
    "    \n",
    "#     print(f\"    üéØ MILESTONE {current_step+1:5d}:\")\n",
    "    \n",
    "#     for window in milestone_windows:\n",
    "#         if len(valid_perf) >= window:\n",
    "#             window_data = valid_perf[-window:]\n",
    "#             window_avg = np.mean(window_data)\n",
    "#             print(f\"       Last {window:4d}: {window_avg:.4f}\")\n",
    "#         else:\n",
    "#             if len(valid_perf) > 10:  # Only show if we have some data\n",
    "#                 window_avg = np.mean(valid_perf)\n",
    "#                 print(f\"       All {len(valid_perf):4d}: {window_avg:.4f}\")\n",
    "#             break\n",
    "\n",
    "# # üî• NEW: Function to detect MAPE trends\n",
    "# def detect_trend_alerts(performance, current_step, alert_window=100):\n",
    "#     \"\"\"Detect if MAPE is trending up or down\"\"\"\n",
    "    \n",
    "#     if current_step < alert_window * 2:\n",
    "#         return\n",
    "    \n",
    "#     valid_perf = performance[:current_step+1][performance[:current_step+1, 0] >= 0, 0]\n",
    "    \n",
    "#     if len(valid_perf) < alert_window * 2:\n",
    "#         return\n",
    "    \n",
    "#     # Compare recent vs earlier performance\n",
    "#     recent_avg = np.mean(valid_perf[-alert_window:])\n",
    "#     earlier_avg = np.mean(valid_perf[-alert_window*2:-alert_window])\n",
    "    \n",
    "#     change_pct = (recent_avg - earlier_avg) / earlier_avg * 100\n",
    "    \n",
    "#     if abs(change_pct) > 10:  # Alert if >10% change\n",
    "#         trend = \"IMPROVING\" if change_pct < 0 else \"DEGRADING\"\n",
    "#         print(f\"    üö® TREND ALERT: MAPE {trend} by {abs(change_pct):.1f}% over last {alert_window} steps\")\n",
    "\n",
    "# # Track performance summary\n",
    "# summary = {}\n",
    "\n",
    "# # Loop over horizons\n",
    "# for j in range(len(horizons)):\n",
    "#     horizon = horizons[j]\n",
    "#     horizon_start_time = time.time()\n",
    "    \n",
    "#     print(f\"\\n[{timestamp()}] üöÄ Starting inference for horizon {horizon}\")\n",
    "#     print(\"=\"*80)\n",
    "\n",
    "#     performance = np.zeros((steps_to_pred, 1))\n",
    "#     predictions = np.zeros((steps_to_pred, 2 * molecules * 3))\n",
    "#     test = create_initial_test_sequence(test_data, seq_length)\n",
    "#     using_ground_truth = True\n",
    "\n",
    "#     for i in range(steps_to_pred):\n",
    "#         prediction = model.predict(test, steps=1, verbose=0)\n",
    "\n",
    "#         if i + seq_length < len(test_data):\n",
    "#             ground_truth = get_ground_truth(test_data, seq_length, i)\n",
    "#             error = tf.metrics.mean_absolute_percentage_error(ground_truth, prediction)\n",
    "#             performance[i, 0] = error\n",
    "#             predictions[i, 0:molecules * 3] = prediction\n",
    "#             predictions[i, molecules * 3:2 * molecules * 3] = ground_truth\n",
    "#         else:\n",
    "#             print(f\"[{timestamp()}] ‚ö†Ô∏è Step {i} exceeds available test data\")\n",
    "#             performance[i, 0] = -1\n",
    "#             predictions[i, 0:molecules * 3] = prediction\n",
    "\n",
    "#         # Track flag\n",
    "#         start_index = len(data) - steps_to_pred - seq_length\n",
    "#         current_index = start_index + i + seq_length\n",
    "#         binary_flag_value = data[current_index, 6]\n",
    "\n",
    "#         full_prediction = np.zeros((1, 7))\n",
    "#         full_prediction[0, :6] = prediction\n",
    "#         full_prediction[0, 6] = binary_flag_value\n",
    "\n",
    "#         # Horizon handling\n",
    "#         if horizon != 1:\n",
    "#             if i % horizon != 0:\n",
    "#                 full_prediction_reshaped = np.expand_dims(full_prediction, axis=1)\n",
    "#                 test = np.append(test[:, 1:, :], full_prediction_reshaped, axis=1)\n",
    "#                 if using_ground_truth:\n",
    "#                     print(f\"[{timestamp()}] Step {i}: üîÅ Switching to auto-regressive prediction\")\n",
    "#                     using_ground_truth = False\n",
    "#             else:\n",
    "#                 if i + seq_length + 1 < len(test_data):\n",
    "#                     test = create_initial_test_sequence(test_data, seq_length, i + 1)\n",
    "#                     print(f\"[{timestamp()}] Step {i}: üîÑ Resetting with ground truth\")\n",
    "#                     using_ground_truth = True\n",
    "#                 else:\n",
    "#                     full_prediction_reshaped = np.expand_dims(full_prediction, axis=1)\n",
    "#                     test = np.append(test[:, 1:, :], full_prediction_reshaped, axis=1)\n",
    "#                     print(f\"[{timestamp()}] Step {i}: Continuing auto-regressive (beyond ground truth)\")\n",
    "#                     using_ground_truth = False\n",
    "#         else:\n",
    "#             if i + seq_length + 1 < len(test_data):\n",
    "#                 test = create_initial_test_sequence(test_data, seq_length, i + 1)\n",
    "#                 using_ground_truth = True\n",
    "#             else:\n",
    "#                 full_prediction_reshaped = np.expand_dims(full_prediction, axis=1)\n",
    "#                 test = np.append(test[:, 1:, :], full_prediction_reshaped, axis=1)\n",
    "#                 print(f\"[{timestamp()}] Step {i}: Switching to auto-regressive (beyond ground truth)\")\n",
    "#                 using_ground_truth = False\n",
    "\n",
    "#         # üî• ENHANCED REPORTING: Multiple reporting triggers\n",
    "#         mode = \"Ground Truth\" if using_ground_truth else \"Auto-Regressive\"\n",
    "        \n",
    "#         # 1. Regular interval reporting\n",
    "#         if (i + 1) % REPORT_INTERVAL == 0 or i == steps_to_pred - 1:\n",
    "#             report_interval_stats(performance, i, REPORT_INTERVAL, mode, horizon_start_time)\n",
    "        \n",
    "#         # 2. Milestone reporting\n",
    "#         if (i + 1) in MILESTONE_INTERVALS:\n",
    "#             report_milestone(performance, i)\n",
    "        \n",
    "#         # 3. Trend detection\n",
    "#         if (i + 1) % 1000 == 0:  # Check trends every 1000 steps\n",
    "#             detect_trend_alerts(performance, i)\n",
    "        \n",
    "#         # 4. Individual step reporting for first few steps\n",
    "#         if i < 10:\n",
    "#             valid_perf = performance[:i+1][performance[:i+1, 0] >= 0, 0]\n",
    "#             if len(valid_perf) > 0:\n",
    "#                 step_mape = performance[i, 0] if performance[i, 0] >= 0 else 0\n",
    "#                 print(f\"    ‚îî‚îÄ Step {i:3d}: Individual MAPE = {step_mape:.4f} | Mode: {mode[:2]}\")\n",
    "        \n",
    "#         # 5. Alert for unusually high individual MAPE\n",
    "#         if i > 100 and performance[i, 0] >= 0:\n",
    "#             # Calculate recent average for comparison\n",
    "#             recent_valid = performance[max(0, i-50):i+1][performance[max(0, i-50):i+1, 0] >= 0, 0]\n",
    "#             if len(recent_valid) > 10:\n",
    "#                 recent_avg = np.mean(recent_valid)\n",
    "#                 current_mape = performance[i, 0]\n",
    "                \n",
    "#                 if current_mape > recent_avg * 3 and current_mape > 1.0:  # Alert threshold\n",
    "#                     print(f\"    ‚ö†Ô∏è  HIGH MAPE Step {i}: {current_mape:.4f} (recent avg: {recent_avg:.4f}) | Mode: {mode[:2]}\")\n",
    "\n",
    "#     print(f\"\\n[{timestamp()}] ‚úÖ Completed prediction loop for horizon {horizon}\")\n",
    "    \n",
    "#     # Save results\n",
    "#     perf_file = f\"11performance_{species}_horizon_{horizon}.csv\"\n",
    "#     pred_file = f\"11predictions_{species}_horizon_{horizon}.csv\"\n",
    "#     print(f\"[{timestamp()}] üíæ Saving results to {perf_file} and {pred_file}\")\n",
    "#     np.savetxt(perf_file, performance, delimiter=\",\")\n",
    "#     np.savetxt(pred_file, predictions, delimiter=\",\")\n",
    "\n",
    "#     # Final statistics for this horizon\n",
    "#     valid_perf = performance[performance[:, 0] >= 0, 0]\n",
    "#     if len(valid_perf) > 0:\n",
    "#         avg_perf = np.mean(valid_perf)\n",
    "#         std_perf = np.std(valid_perf)\n",
    "#         median_perf = np.median(valid_perf)\n",
    "#         min_perf = np.min(valid_perf)\n",
    "#         max_perf = np.max(valid_perf)\n",
    "#         horizon_time = time.time() - horizon_start_time\n",
    "        \n",
    "#         print(f\"\\n[{timestamp()}] üìä FINAL STATISTICS for Horizon {horizon}:\")\n",
    "#         print(f\"    Average MAPE: {avg_perf:.4f} ¬± {std_perf:.4f}\")\n",
    "#         print(f\"    Median MAPE:  {median_perf:.4f}\")\n",
    "#         print(f\"    Range:        {min_perf:.4f} - {max_perf:.4f}\")\n",
    "#         print(f\"    Valid predictions: {len(valid_perf)}/{steps_to_pred} ({len(valid_perf)/steps_to_pred*100:.1f}%)\")\n",
    "#         print(f\"    Total time: {horizon_time:.1f} seconds ({horizon_time/60:.1f} minutes)\")\n",
    "        \n",
    "#         summary[horizon] = avg_perf\n",
    "#     else:\n",
    "#         print(f\"[{timestamp()}] ‚ùå No valid performance data for horizon {horizon}\")\n",
    "#         summary[horizon] = None\n",
    "\n",
    "# # Final summary\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(f\"[{timestamp()}] üßæ FINAL SUMMARY - Average MAPE by Horizon:\")\n",
    "# print(f\"{'='*80}\")\n",
    "# for h, v in summary.items():\n",
    "#     if v is not None:\n",
    "#         print(f\"Horizon {h:4d}: {v:.4f}\")\n",
    "#     else:\n",
    "#         print(f\"Horizon {h:4d}: No valid data\")\n",
    "\n",
    "# print(f\"\\n[{timestamp()}] üéâ Inference completed for all horizons!\")\n",
    "\n",
    "# # Save summary to CSV\n",
    "# summary_data = [[h, v if v is not None else -1] for h, v in summary.items()]\n",
    "# summary_df = pd.DataFrame(summary_data, columns=['Horizon', 'Avg_MAPE'])\n",
    "# summary_file = f\"summary_{species}_enhanced.csv\"\n",
    "# summary_df.to_csv(summary_file, index=False)\n",
    "# print(f\"[{timestamp()}] üíæ Enhanced summary saved to {summary_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d1906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:03:16] üîß CORRECTED INFERENCE SETUP:\n",
      "   Training used: 8000 samples\n",
      "   Total dataset: 20000 samples\n",
      "   Predicting: 12000 steps beyond training\n",
      "   Available for prediction: 12000 = 12000 samples\n",
      "[2025-07-06 19:03:16] üìÅ Loaded full dataset: (20000, 7)\n",
      "[2025-07-06 19:03:16] üìÅ Using dataset: (20000, 7)\n",
      "[2025-07-06 19:03:16] üîÑ Data split:\n",
      "   Training context: (8000, 7) (samples 0 to 7999)\n",
      "   Prediction range: (12000, 7) (samples 8000 to 19999)\n",
      "[2025-07-06 19:03:16] ‚ö° Binary flag analysis:\n",
      "   Total '1' flags: 200\n",
      "   Pattern check - first 10 indices: [ 99 199 299 399 499 599 699 799 899 999]\n",
      "   Expected pattern: every 100 steps starting from some offset\n",
      "   Intervals between flags: [100 100 100 100 100 100 100 100 100 100] (should be mostly 100)\n",
      "\n",
      "[2025-07-06 19:03:16] üöÄ Starting corrected inference...\n",
      "[2025-07-06 19:03:17] ‚úÖ Model loaded: (None, 20, 7) ‚Üí (None, 6)\n",
      "\n",
      "[2025-07-06 19:03:17] üéØ Starting horizon 1\n",
      "================================================================================\n",
      "[2025-07-06 19:03:17] üîÑ Initial sequence shape: (1, 20, 7)\n",
      "   Starting from training samples 7980 to 7999\n",
      "[2025-07-06 19:03:19] Step     1/12000 | Pos:  8000 | MAPE: 0.0284 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:19] Step     2/12000 | Pos:  8001 | MAPE: 0.0312 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:19] Step     3/12000 | Pos:  8002 | MAPE: 0.0315 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:19] Step     4/12000 | Pos:  8003 | MAPE: 0.0371 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:19] Step     5/12000 | Pos:  8004 | MAPE: 0.0332 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:19] Step     6/12000 | Pos:  8005 | MAPE: 0.0314 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:19] Step     7/12000 | Pos:  8006 | MAPE: 0.0304 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:19] Step     8/12000 | Pos:  8007 | MAPE: 0.0312 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:19] Step     9/12000 | Pos:  8008 | MAPE: 0.0332 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:19] Step    10/12000 | Pos:  8009 | MAPE: 0.0331 | Flag: 0.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:03:49] Step   500/12000 | Pos:  8499 | MAPE: 0.0138 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:04:21] Step  1000/12000 | Pos:  8999 | MAPE: 0.0134 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:04:52] Step  1500/12000 | Pos:  9499 | MAPE: 0.0112 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:05:23] Step  2000/12000 | Pos:  9999 | MAPE: 0.0099 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:05:54] Step  2500/12000 | Pos: 10499 | MAPE: 0.0094 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:06:26] Step  3000/12000 | Pos: 10999 | MAPE: 0.0088 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:06:57] Step  3500/12000 | Pos: 11499 | MAPE: 0.0082 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:07:29] Step  4000/12000 | Pos: 11999 | MAPE: 0.0078 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:07:59] Step  4500/12000 | Pos: 12499 | MAPE: 0.1009 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:08:28] Step  5000/12000 | Pos: 12999 | MAPE: 0.4435 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:08:55] Step  5500/12000 | Pos: 13499 | MAPE: 0.6869 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:09:25] Step  6000/12000 | Pos: 13999 | MAPE: 1.0277 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:09:55] Step  6500/12000 | Pos: 14499 | MAPE: 1.3983 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:10:30] Step  7000/12000 | Pos: 14999 | MAPE: 1.6606 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:11:16] Step  7500/12000 | Pos: 15499 | MAPE: 1.8041 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:11:52] Step  8000/12000 | Pos: 15999 | MAPE: 1.9522 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:12:21] Step  8500/12000 | Pos: 16499 | MAPE: 2.0744 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:12:58] Step  9000/12000 | Pos: 16999 | MAPE: 2.2163 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:13:36] Step  9500/12000 | Pos: 17499 | MAPE: 2.4051 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:14:15] Step 10000/12000 | Pos: 17999 | MAPE: 2.6065 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:14:54] Step 10500/12000 | Pos: 18499 | MAPE: 2.8328 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:15:33] Step 11000/12000 | Pos: 18999 | MAPE: 3.0553 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:16:13] Step 11500/12000 | Pos: 19499 | MAPE: 3.2856 | Flag: 1.0 | Mode: Ground Truth\n",
      "[2025-07-06 19:16:50] Step 12000/12000 | Pos: 19999 | MAPE: 3.5435 | Flag: 1.0 | Mode: Ground Truth\n",
      "\n",
      "[2025-07-06 19:16:50] ‚úÖ Horizon 1 completed:\n",
      "   Average MAPE: 3.5435\n",
      "   Valid predictions: 12000/12000\n",
      "\n",
      "[2025-07-06 19:16:50] üéØ Starting horizon 5\n",
      "================================================================================\n",
      "[2025-07-06 19:16:50] üîÑ Initial sequence shape: (1, 20, 7)\n",
      "   Starting from training samples 7980 to 7999\n",
      "[2025-07-06 19:16:50] Step     1/12000 | Pos:  8000 | MAPE: 0.0284 | Flag: 0.0 | Mode: Ground Truth Reset\n",
      "[2025-07-06 19:16:50] Step     2/12000 | Pos:  8001 | MAPE: 0.0312 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:16:50] Step     3/12000 | Pos:  8002 | MAPE: 0.0323 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:16:50] Step     4/12000 | Pos:  8003 | MAPE: 0.0381 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:16:50] Step     5/12000 | Pos:  8004 | MAPE: 0.0337 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:16:50] Step     6/12000 | Pos:  8005 | MAPE: 0.0328 | Flag: 0.0 | Mode: Ground Truth Reset\n",
      "[2025-07-06 19:16:50] Step     7/12000 | Pos:  8006 | MAPE: 0.0316 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:16:50] Step     8/12000 | Pos:  8007 | MAPE: 0.0325 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:16:51] Step     9/12000 | Pos:  8008 | MAPE: 0.0349 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:16:51] Step    10/12000 | Pos:  8009 | MAPE: 0.0354 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:17:29] Step   500/12000 | Pos:  8499 | MAPE: 0.0155 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:18:08] Step  1000/12000 | Pos:  8999 | MAPE: 0.0150 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:18:47] Step  1500/12000 | Pos:  9499 | MAPE: 0.0125 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:19:24] Step  2000/12000 | Pos:  9999 | MAPE: 0.0110 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:20:06] Step  2500/12000 | Pos: 10499 | MAPE: 0.0102 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:20:52] Step  3000/12000 | Pos: 10999 | MAPE: 0.0096 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:21:34] Step  3500/12000 | Pos: 11499 | MAPE: 0.0089 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:22:16] Step  4000/12000 | Pos: 11999 | MAPE: 0.0084 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:22:59] Step  4500/12000 | Pos: 12499 | MAPE: 0.1018 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:23:41] Step  5000/12000 | Pos: 12999 | MAPE: 0.4450 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:24:22] Step  5500/12000 | Pos: 13499 | MAPE: 0.6878 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:25:08] Step  6000/12000 | Pos: 13999 | MAPE: 1.0294 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:25:53] Step  6500/12000 | Pos: 14499 | MAPE: 1.4012 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:26:36] Step  7000/12000 | Pos: 14999 | MAPE: 1.6648 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:27:22] Step  7500/12000 | Pos: 15499 | MAPE: 1.8079 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:28:08] Step  8000/12000 | Pos: 15999 | MAPE: 1.9551 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:28:50] Step  8500/12000 | Pos: 16499 | MAPE: 2.0771 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:29:37] Step  9000/12000 | Pos: 16999 | MAPE: 2.2190 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:30:30] Step  9500/12000 | Pos: 17499 | MAPE: 2.4079 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:31:12] Step 10000/12000 | Pos: 17999 | MAPE: 2.6094 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:31:58] Step 10500/12000 | Pos: 18499 | MAPE: 2.8359 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:32:47] Step 11000/12000 | Pos: 18999 | MAPE: 3.0583 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:33:32] Step 11500/12000 | Pos: 19499 | MAPE: 3.2886 | Flag: 1.0 | Mode: Auto-Regressive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:34:21] Step 12000/12000 | Pos: 19999 | MAPE: 3.5466 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "\n",
      "[2025-07-06 19:34:22] ‚úÖ Horizon 5 completed:\n",
      "   Average MAPE: 3.5466\n",
      "   Valid predictions: 12000/12000\n",
      "\n",
      "[2025-07-06 19:34:22] üéØ Starting horizon 10\n",
      "================================================================================\n",
      "[2025-07-06 19:34:22] üîÑ Initial sequence shape: (1, 20, 7)\n",
      "   Starting from training samples 7980 to 7999\n",
      "[2025-07-06 19:34:22] Step     1/12000 | Pos:  8000 | MAPE: 0.0284 | Flag: 0.0 | Mode: Ground Truth Reset\n",
      "[2025-07-06 19:34:22] Step     2/12000 | Pos:  8001 | MAPE: 0.0312 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:34:22] Step     3/12000 | Pos:  8002 | MAPE: 0.0323 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:34:22] Step     4/12000 | Pos:  8003 | MAPE: 0.0381 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:34:22] Step     5/12000 | Pos:  8004 | MAPE: 0.0337 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:34:22] Step     6/12000 | Pos:  8005 | MAPE: 0.0328 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:34:22] Step     7/12000 | Pos:  8006 | MAPE: 0.0328 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:34:22] Step     8/12000 | Pos:  8007 | MAPE: 0.0350 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:34:23] Step     9/12000 | Pos:  8008 | MAPE: 0.0385 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:34:23] Step    10/12000 | Pos:  8009 | MAPE: 0.0399 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:35:05] Step   500/12000 | Pos:  8499 | MAPE: 0.0191 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:36:27] Step  1000/12000 | Pos:  8999 | MAPE: 0.0187 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:37:09] Step  1500/12000 | Pos:  9499 | MAPE: 0.0153 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:37:53] Step  2000/12000 | Pos:  9999 | MAPE: 0.0132 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:38:35] Step  2500/12000 | Pos: 10499 | MAPE: 0.0121 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:39:14] Step  3000/12000 | Pos: 10999 | MAPE: 0.0112 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:39:51] Step  3500/12000 | Pos: 11499 | MAPE: 0.0103 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:40:46] Step  4000/12000 | Pos: 11999 | MAPE: 0.0097 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:41:26] Step  4500/12000 | Pos: 12499 | MAPE: 0.1037 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:42:08] Step  5000/12000 | Pos: 12999 | MAPE: 0.4491 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:42:48] Step  5500/12000 | Pos: 13499 | MAPE: 0.6930 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:43:29] Step  6000/12000 | Pos: 13999 | MAPE: 1.0409 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:44:16] Step  6500/12000 | Pos: 14499 | MAPE: 1.4220 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:44:57] Step  7000/12000 | Pos: 14999 | MAPE: 1.6916 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:45:39] Step  7500/12000 | Pos: 15499 | MAPE: 1.8349 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:46:46] Step  8000/12000 | Pos: 15999 | MAPE: 1.9803 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:47:40] Step  8500/12000 | Pos: 16499 | MAPE: 2.1011 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:48:26] Step  9000/12000 | Pos: 16999 | MAPE: 2.2418 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:49:11] Step  9500/12000 | Pos: 17499 | MAPE: 2.4301 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:49:55] Step 10000/12000 | Pos: 17999 | MAPE: 2.6319 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:50:38] Step 10500/12000 | Pos: 18499 | MAPE: 2.8599 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:51:20] Step 11000/12000 | Pos: 18999 | MAPE: 3.0839 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:03] Step 11500/12000 | Pos: 19499 | MAPE: 3.3159 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:43] Step 12000/12000 | Pos: 19999 | MAPE: 3.5762 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "\n",
      "[2025-07-06 19:52:43] ‚úÖ Horizon 10 completed:\n",
      "   Average MAPE: 3.5762\n",
      "   Valid predictions: 12000/12000\n",
      "\n",
      "[2025-07-06 19:52:43] üéØ Starting horizon 20\n",
      "================================================================================\n",
      "[2025-07-06 19:52:43] üîÑ Initial sequence shape: (1, 20, 7)\n",
      "   Starting from training samples 7980 to 7999\n",
      "[2025-07-06 19:52:43] Step     1/12000 | Pos:  8000 | MAPE: 0.0284 | Flag: 0.0 | Mode: Ground Truth Reset\n",
      "[2025-07-06 19:52:43] Step     2/12000 | Pos:  8001 | MAPE: 0.0312 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:43] Step     3/12000 | Pos:  8002 | MAPE: 0.0323 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:44] Step     4/12000 | Pos:  8003 | MAPE: 0.0381 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:44] Step     5/12000 | Pos:  8004 | MAPE: 0.0337 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:44] Step     6/12000 | Pos:  8005 | MAPE: 0.0328 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:44] Step     7/12000 | Pos:  8006 | MAPE: 0.0328 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:44] Step     8/12000 | Pos:  8007 | MAPE: 0.0350 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:44] Step     9/12000 | Pos:  8008 | MAPE: 0.0385 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:52:44] Step    10/12000 | Pos:  8009 | MAPE: 0.0399 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:53:24] Step   500/12000 | Pos:  8499 | MAPE: 0.0280 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:53:59] Step  1000/12000 | Pos:  8999 | MAPE: 0.0280 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:54:33] Step  1500/12000 | Pos:  9499 | MAPE: 0.0220 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:55:06] Step  2000/12000 | Pos:  9999 | MAPE: 0.0185 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:55:41] Step  2500/12000 | Pos: 10499 | MAPE: 0.0166 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:56:16] Step  3000/12000 | Pos: 10999 | MAPE: 0.0151 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:56:49] Step  3500/12000 | Pos: 11499 | MAPE: 0.0137 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:57:24] Step  4000/12000 | Pos: 11999 | MAPE: 0.0127 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:57:56] Step  4500/12000 | Pos: 12499 | MAPE: 0.1098 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:58:29] Step  5000/12000 | Pos: 12999 | MAPE: 0.4429 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:59:02] Step  5500/12000 | Pos: 13499 | MAPE: 0.6743 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 19:59:34] Step  6000/12000 | Pos: 13999 | MAPE: 1.0120 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:00:13] Step  6500/12000 | Pos: 14499 | MAPE: 1.3852 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:01:16] Step  7000/12000 | Pos: 14999 | MAPE: 1.6503 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:01:48] Step  7500/12000 | Pos: 15499 | MAPE: 1.7881 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:02:21] Step  8000/12000 | Pos: 15999 | MAPE: 1.9406 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:02:54] Step  8500/12000 | Pos: 16499 | MAPE: 2.0706 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:03:26] Step  9000/12000 | Pos: 16999 | MAPE: 2.2221 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:04:03] Step  9500/12000 | Pos: 17499 | MAPE: 2.4185 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:04:36] Step 10000/12000 | Pos: 17999 | MAPE: 2.6258 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:05:08] Step 10500/12000 | Pos: 18499 | MAPE: 2.8535 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:05:42] Step 11000/12000 | Pos: 18999 | MAPE: 3.0793 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:06:17] Step 11500/12000 | Pos: 19499 | MAPE: 3.3136 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-07-06 20:06:50] Step 12000/12000 | Pos: 19999 | MAPE: 3.5737 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "\n",
      "[2025-07-06 20:06:50] ‚úÖ Horizon 20 completed:\n",
      "   Average MAPE: 3.5737\n",
      "   Valid predictions: 12000/12000\n",
      "\n",
      "================================================================================\n",
      "[2025-07-06 20:06:50] üéâ CORRECTED INFERENCE COMPLETED\n",
      "================================================================================\n",
      "Horizon    1: 3.5435 MAPE\n",
      "Horizon    5: 3.5466 MAPE\n",
      "Horizon   10: 3.5762 MAPE\n",
      "Horizon   20: 3.5737 MAPE\n",
      "\n",
      "[2025-07-06 20:06:50] üí° Key corrections made:\n",
      "   ‚úÖ Start prediction from end of training data (sample 8000)\n",
      "   ‚úÖ Use correct binary flags from proper temporal positions\n",
      "   ‚úÖ Handle ground truth availability correctly\n",
      "   ‚úÖ Maintain proper sequence continuity\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from keras.models import load_model\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# def timestamp(): \n",
    "#     return time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# # ============================================================================\n",
    "# # CORRECTED PARAMETERS AND DATA HANDLING\n",
    "# # ============================================================================\n",
    "\n",
    "# # Key parameters\n",
    "# TRAINING_SAMPLES = 8000      # Samples used for training\n",
    "# TOTAL_SAMPLES = 20000        # Total samples in dataset\n",
    "# seq_length = 20\n",
    "# steps_to_pred = 12000        # How many steps to predict beyond training\n",
    "# batch_size = 32\n",
    "# molecules = 2\n",
    "# species = '2_22'\n",
    "# horizons = np.array([1, 5, 10, 20])\n",
    "\n",
    "# print(f\"[{timestamp()}] üîß CORRECTED INFERENCE SETUP:\")\n",
    "# print(f\"   Training used: {TRAINING_SAMPLES} samples\")\n",
    "# print(f\"   Total dataset: {TOTAL_SAMPLES} samples\") \n",
    "# print(f\"   Predicting: {steps_to_pred} steps beyond training\")\n",
    "# print(f\"   Available for prediction: {TOTAL_SAMPLES - TRAINING_SAMPLES} = {TOTAL_SAMPLES - TRAINING_SAMPLES} samples\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # LOAD AND VERIFY DATA\n",
    "# # ============================================================================\n",
    "\n",
    "# # Load the FULL dataset\n",
    "# full_data = np.load(f'{species}_data.npy')\n",
    "# print(f\"[{timestamp()}] üìÅ Loaded full dataset: {full_data.shape}\")\n",
    "\n",
    "# # Verify we have enough data\n",
    "# if TOTAL_SAMPLES > len(full_data):\n",
    "#     print(f\"‚ùå Error: Dataset only has {len(full_data)} samples, need {TOTAL_SAMPLES}\")\n",
    "#     exit(1)\n",
    "\n",
    "# if TRAINING_SAMPLES + steps_to_pred > TOTAL_SAMPLES:\n",
    "#     print(f\"‚ùå Error: Training ({TRAINING_SAMPLES}) + prediction ({steps_to_pred}) > total ({TOTAL_SAMPLES})\")\n",
    "#     exit(1)\n",
    "\n",
    "# # Use only the specified amount\n",
    "# full_data = full_data[:TOTAL_SAMPLES, :]\n",
    "# print(f\"[{timestamp()}] üìÅ Using dataset: {full_data.shape}\")\n",
    "\n",
    "# # Split data correctly\n",
    "# training_data = full_data[:TRAINING_SAMPLES, :]          # First 8,000 for training context\n",
    "# prediction_data = full_data[TRAINING_SAMPLES:, :]        # Remaining for prediction/validation\n",
    "\n",
    "# print(f\"[{timestamp()}] üîÑ Data split:\")\n",
    "# print(f\"   Training context: {training_data.shape} (samples 0 to {TRAINING_SAMPLES-1})\")\n",
    "# print(f\"   Prediction range: {prediction_data.shape} (samples {TRAINING_SAMPLES} to {TOTAL_SAMPLES-1})\")\n",
    "\n",
    "# # Verify binary flags in full dataset\n",
    "# binary_flags = full_data[:, 6]\n",
    "# ones_indices = np.where(binary_flags == 1)[0]\n",
    "# print(f\"[{timestamp()}] ‚ö° Binary flag analysis:\")\n",
    "# print(f\"   Total '1' flags: {len(ones_indices)}\")\n",
    "# print(f\"   Pattern check - first 10 indices: {ones_indices[:10]}\")\n",
    "# print(f\"   Expected pattern: every 100 steps starting from some offset\")\n",
    "\n",
    "# # Check if pattern is every 100 steps\n",
    "# if len(ones_indices) > 1:\n",
    "#     differences = np.diff(ones_indices)\n",
    "#     print(f\"   Intervals between flags: {differences[:10]} (should be mostly 100)\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # CORRECTED INFERENCE SETUP\n",
    "# # ============================================================================\n",
    "\n",
    "# def create_initial_sequence_from_training(training_data, seq_length):\n",
    "#     \"\"\"Create initial sequence from the LAST part of training data\"\"\"\n",
    "#     if len(training_data) < seq_length:\n",
    "#         raise ValueError(f\"Training data too short: {len(training_data)} < {seq_length}\")\n",
    "    \n",
    "#     # Take the last seq_length samples from training\n",
    "#     sequence = training_data[-seq_length:, :]\n",
    "#     return np.expand_dims(sequence, axis=0)\n",
    "\n",
    "# def get_correct_binary_flag(full_data, training_samples, prediction_step):\n",
    "#     \"\"\"Get the correct binary flag for a given prediction step\"\"\"\n",
    "#     # The actual position in the full dataset\n",
    "#     actual_position = training_samples + prediction_step\n",
    "    \n",
    "#     if actual_position >= len(full_data):\n",
    "#         # If we've gone beyond available data, extrapolate the pattern\n",
    "#         # Assuming the pattern repeats every 100 steps\n",
    "#         ones_indices = np.where(full_data[:, 6] == 1)[0]\n",
    "#         if len(ones_indices) > 0:\n",
    "#             # Find the pattern\n",
    "#             pattern_start = ones_indices[0] % 100\n",
    "#             flag_value = 1 if (actual_position % 100) == pattern_start else 0\n",
    "#             print(f\"   ‚ö° Extrapolating flag for position {actual_position}: {flag_value}\")\n",
    "#             return flag_value\n",
    "#         else:\n",
    "#             return 0\n",
    "    \n",
    "#     return full_data[actual_position, 6]\n",
    "\n",
    "# def get_ground_truth_if_available(full_data, training_samples, prediction_step):\n",
    "#     \"\"\"Get ground truth if available, otherwise return None\"\"\"\n",
    "#     actual_position = training_samples + prediction_step\n",
    "    \n",
    "#     if actual_position < len(full_data):\n",
    "#         return full_data[actual_position, :6].reshape(1, -1)\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # ============================================================================\n",
    "# # CORRECTED INFERENCE LOOP\n",
    "# # ============================================================================\n",
    "\n",
    "# print(f\"\\n[{timestamp()}] üöÄ Starting corrected inference...\")\n",
    "\n",
    "# # Load model\n",
    "# model = load_model(f'transformer_model_384_{species}.h5')\n",
    "# print(f\"[{timestamp()}] ‚úÖ Model loaded: {model.input_shape} ‚Üí {model.output_shape}\")\n",
    "\n",
    "# # Track performance summary\n",
    "# summary = {}\n",
    "\n",
    "# for j, horizon in enumerate(horizons):\n",
    "#     horizon_start_time = time.time()\n",
    "    \n",
    "#     print(f\"\\n[{timestamp()}] üéØ Starting horizon {horizon}\")\n",
    "#     print(\"=\"*80)\n",
    "    \n",
    "#     # Initialize tracking\n",
    "#     performance = np.zeros((steps_to_pred, 1))\n",
    "#     predictions = np.zeros((steps_to_pred, 2 * molecules * 3))\n",
    "    \n",
    "#     # Start with the last sequence from training data\n",
    "#     current_sequence = create_initial_sequence_from_training(training_data, seq_length)\n",
    "#     print(f\"[{timestamp()}] üîÑ Initial sequence shape: {current_sequence.shape}\")\n",
    "#     print(f\"   Starting from training samples {TRAINING_SAMPLES-seq_length} to {TRAINING_SAMPLES-1}\")\n",
    "    \n",
    "#     using_ground_truth = True\n",
    "    \n",
    "#     for i in range(steps_to_pred):\n",
    "#         # Make prediction\n",
    "#         prediction = model.predict(current_sequence, steps=1, verbose=0)\n",
    "        \n",
    "#         # Get ground truth if available\n",
    "#         ground_truth = get_ground_truth_if_available(full_data, TRAINING_SAMPLES, i)\n",
    "        \n",
    "#         # Calculate performance if ground truth available\n",
    "#         if ground_truth is not None:\n",
    "#             error = tf.metrics.mean_absolute_percentage_error(ground_truth, prediction)\n",
    "#             performance[i, 0] = error.numpy()\n",
    "#             predictions[i, :molecules*3] = prediction.flatten()\n",
    "#             predictions[i, molecules*3:] = ground_truth.flatten()\n",
    "#         else:\n",
    "#             performance[i, 0] = -1  # No ground truth available\n",
    "#             predictions[i, :molecules*3] = prediction.flatten()\n",
    "#             if i == 0:\n",
    "#                 print(f\"[{timestamp()}] ‚ö†Ô∏è  No more ground truth available from step {i}\")\n",
    "        \n",
    "#         # Get the correct binary flag\n",
    "#         binary_flag = get_correct_binary_flag(full_data, TRAINING_SAMPLES, i)\n",
    "        \n",
    "#         # Create full prediction (coordinates + binary flag)\n",
    "#         full_prediction = np.zeros((1, 7))\n",
    "#         full_prediction[0, :6] = prediction.flatten()\n",
    "#         full_prediction[0, 6] = binary_flag\n",
    "        \n",
    "#         # Update sequence based on horizon strategy\n",
    "#         if horizon == 1:\n",
    "#             # Always use ground truth if available, otherwise use prediction\n",
    "#             if ground_truth is not None:\n",
    "#                 next_step = np.zeros((1, 7))\n",
    "#                 next_step[0, :6] = ground_truth.flatten()\n",
    "#                 next_step[0, 6] = binary_flag\n",
    "#                 current_sequence = np.concatenate([current_sequence[:, 1:, :], \n",
    "#                                                  next_step.reshape(1, 1, -1)], axis=1)\n",
    "#                 mode = \"Ground Truth\"\n",
    "#             else:\n",
    "#                 current_sequence = np.concatenate([current_sequence[:, 1:, :], \n",
    "#                                                  full_prediction.reshape(1, 1, -1)], axis=1)\n",
    "#                 mode = \"Auto-Regressive\"\n",
    "#                 using_ground_truth = False\n",
    "                \n",
    "#         else:\n",
    "#             # Multi-step horizon strategy\n",
    "#             if i % horizon == 0 and ground_truth is not None:\n",
    "#                 # Reset with ground truth every 'horizon' steps\n",
    "#                 reset_start = max(0, TRAINING_SAMPLES + i - seq_length + 1)\n",
    "#                 reset_end = TRAINING_SAMPLES + i + 1\n",
    "                \n",
    "#                 if reset_end <= len(full_data):\n",
    "#                     current_sequence = full_data[reset_start:reset_end, :].reshape(1, seq_length, -1)\n",
    "#                     mode = \"Ground Truth Reset\"\n",
    "#                     using_ground_truth = True\n",
    "#                 else:\n",
    "#                     # Continue with prediction\n",
    "#                     current_sequence = np.concatenate([current_sequence[:, 1:, :], \n",
    "#                                                      full_prediction.reshape(1, 1, -1)], axis=1)\n",
    "#                     mode = \"Auto-Regressive\"\n",
    "#                     using_ground_truth = False\n",
    "#             else:\n",
    "#                 # Continue with previous prediction\n",
    "#                 current_sequence = np.concatenate([current_sequence[:, 1:, :], \n",
    "#                                                  full_prediction.reshape(1, 1, -1)], axis=1)\n",
    "#                 mode = \"Auto-Regressive\"\n",
    "#                 using_ground_truth = False\n",
    "        \n",
    "#         # Progress reporting\n",
    "#         if (i + 1) % 500 == 0 or i < 10:\n",
    "#             actual_pos = TRAINING_SAMPLES + i\n",
    "#             valid_perf = performance[:i+1][performance[:i+1, 0] >= 0, 0]\n",
    "            \n",
    "#             if len(valid_perf) > 0:\n",
    "#                 avg_mape = np.mean(valid_perf)\n",
    "#                 print(f\"[{timestamp()}] Step {i+1:5d}/{steps_to_pred} | Pos: {actual_pos:5d} | \"\n",
    "#                       f\"MAPE: {avg_mape:.4f} | Flag: {binary_flag} | Mode: {mode}\")\n",
    "#             else:\n",
    "#                 print(f\"[{timestamp()}] Step {i+1:5d}/{steps_to_pred} | Pos: {actual_pos:5d} | \"\n",
    "#                       f\"No valid MAPE | Flag: {binary_flag} | Mode: {mode}\")\n",
    "    \n",
    "#     # Save results\n",
    "#     perf_file = f\"corrected_performance_{species}_horizon_{horizon}.csv\"\n",
    "#     pred_file = f\"corrected_predictions_{species}_horizon_{horizon}.csv\"\n",
    "#     np.savetxt(perf_file, performance, delimiter=\",\")\n",
    "#     np.savetxt(pred_file, predictions, delimiter=\",\")\n",
    "    \n",
    "#     # Calculate final statistics\n",
    "#     valid_perf = performance[performance[:, 0] >= 0, 0]\n",
    "#     if len(valid_perf) > 0:\n",
    "#         avg_perf = np.mean(valid_perf)\n",
    "#         print(f\"\\n[{timestamp()}] ‚úÖ Horizon {horizon} completed:\")\n",
    "#         print(f\"   Average MAPE: {avg_perf:.4f}\")\n",
    "#         print(f\"   Valid predictions: {len(valid_perf)}/{steps_to_pred}\")\n",
    "#         summary[horizon] = avg_perf\n",
    "#     else:\n",
    "#         print(f\"\\n[{timestamp()}] ‚ùå Horizon {horizon}: No valid predictions\")\n",
    "#         summary[horizon] = None\n",
    "\n",
    "# # Final summary\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(f\"[{timestamp()}] üéâ CORRECTED INFERENCE COMPLETED\")\n",
    "# print(f\"{'='*80}\")\n",
    "# for h, v in summary.items():\n",
    "#     if v is not None:\n",
    "#         print(f\"Horizon {h:4d}: {v:.4f} MAPE\")\n",
    "#     else:\n",
    "#         print(f\"Horizon {h:4d}: No valid data\")\n",
    "\n",
    "# print(f\"\\n[{timestamp()}] üí° Key corrections made:\")\n",
    "# print(f\"   ‚úÖ Start prediction from end of training data (sample {TRAINING_SAMPLES})\")\n",
    "# print(f\"   ‚úÖ Use correct binary flags from proper temporal positions\")\n",
    "# print(f\"   ‚úÖ Handle ground truth availability correctly\")\n",
    "# print(f\"   ‚úÖ Maintain proper sequence continuity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1ae9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mali19\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[2025-08-14 22:25:45] üîß CORRECTED INFERENCE SETUP:\n",
      "   Training used: 8000 samples\n",
      "   Total dataset: 20000 samples\n",
      "   Predicting: 12000 steps beyond training\n",
      "   Available for prediction: 12000 = 12000 samples\n",
      "[2025-08-14 22:25:45] üìÅ Loaded full dataset: (20000, 7)\n",
      "[2025-08-14 22:25:45] üìÅ Using dataset: (20000, 7)\n",
      "[2025-08-14 22:25:45] üîÑ Data split:\n",
      "   Training context: (8000, 7) (samples 0 to 7999)\n",
      "   Prediction range: (12000, 7) (samples 8000 to 19999)\n",
      "[2025-08-14 22:25:45] ‚ö° Binary flag analysis:\n",
      "   Total '1' flags: 200\n",
      "   Pattern check - first 10 indices: [ 99 199 299 399 499 599 699 799 899 999]\n",
      "   Expected pattern: every 100 steps starting from some offset\n",
      "   Intervals between flags: [100 100 100 100 100 100 100 100 100 100] (should be mostly 100)\n",
      "\n",
      "[2025-08-14 22:25:45] üöÄ Starting corrected inference...\n",
      "WARNING:tensorflow:From C:\\Users\\mali19\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "[2025-08-14 22:25:52] ‚úÖ Model loaded: (None, 20, 7) ‚Üí (None, 6)\n",
      "\n",
      "[2025-08-14 22:25:52] üéØ Starting horizon 50\n",
      "================================================================================\n",
      "[2025-08-14 22:25:52] üîÑ Initial sequence shape: (1, 20, 7)\n",
      "   Starting from training samples 7980 to 7999\n",
      "[2025-08-14 22:25:55] Step     1/12000 | Pos:  8000 | MAPE: 0.0225 | Flag: 0.0 | Mode: Ground Truth Reset\n",
      "[2025-08-14 22:25:55] Step     2/12000 | Pos:  8001 | MAPE: 0.0215 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:25:55] Step     3/12000 | Pos:  8002 | MAPE: 0.0233 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:25:56] Step     4/12000 | Pos:  8003 | MAPE: 0.0263 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:25:56] Step     5/12000 | Pos:  8004 | MAPE: 0.0311 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:25:56] Step     6/12000 | Pos:  8005 | MAPE: 0.0369 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:25:56] Step     7/12000 | Pos:  8006 | MAPE: 0.0434 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:25:56] Step     8/12000 | Pos:  8007 | MAPE: 0.0507 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:25:57] Step     9/12000 | Pos:  8008 | MAPE: 0.0584 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:25:57] Step    10/12000 | Pos:  8009 | MAPE: 0.0666 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:27:24] Step   500/12000 | Pos:  8499 | MAPE: 0.2407 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:28:47] Step  1000/12000 | Pos:  8999 | MAPE: 0.2106 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:30:09] Step  1500/12000 | Pos:  9499 | MAPE: 0.1825 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:31:32] Step  2000/12000 | Pos:  9999 | MAPE: 0.1706 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:32:54] Step  2500/12000 | Pos: 10499 | MAPE: 0.1528 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:34:17] Step  3000/12000 | Pos: 10999 | MAPE: 0.1327 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:35:39] Step  3500/12000 | Pos: 11499 | MAPE: 0.1153 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:37:02] Step  4000/12000 | Pos: 11999 | MAPE: 0.1063 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:38:23] Step  4500/12000 | Pos: 12499 | MAPE: 0.2093 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:39:46] Step  5000/12000 | Pos: 12999 | MAPE: 0.4475 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:41:08] Step  5500/12000 | Pos: 13499 | MAPE: 0.6141 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:42:31] Step  6000/12000 | Pos: 13999 | MAPE: 0.8024 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:43:55] Step  6500/12000 | Pos: 14499 | MAPE: 1.0004 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:45:19] Step  7000/12000 | Pos: 14999 | MAPE: 4.0817 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:46:43] Step  7500/12000 | Pos: 15499 | MAPE: 4.5530 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:48:06] Step  8000/12000 | Pos: 15999 | MAPE: 4.5697 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:49:29] Step  8500/12000 | Pos: 16499 | MAPE: 4.5482 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:50:54] Step  9000/12000 | Pos: 16999 | MAPE: 4.5970 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:52:15] Step  9500/12000 | Pos: 17499 | MAPE: 4.7353 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:53:40] Step 10000/12000 | Pos: 17999 | MAPE: 4.8862 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:55:03] Step 10500/12000 | Pos: 18499 | MAPE: 5.0262 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:56:24] Step 11000/12000 | Pos: 18999 | MAPE: 5.1495 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:57:46] Step 11500/12000 | Pos: 19499 | MAPE: 5.3210 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:59:06] Step 12000/12000 | Pos: 19999 | MAPE: 5.5260 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "\n",
      "[2025-08-14 22:59:06] ‚úÖ Horizon 50 completed:\n",
      "   Average MAPE: 5.5260\n",
      "   Valid predictions: 12000/12000\n",
      "\n",
      "[2025-08-14 22:59:06] üéØ Starting horizon 100\n",
      "================================================================================\n",
      "[2025-08-14 22:59:06] üîÑ Initial sequence shape: (1, 20, 7)\n",
      "   Starting from training samples 7980 to 7999\n",
      "[2025-08-14 22:59:06] Step     1/12000 | Pos:  8000 | MAPE: 0.0225 | Flag: 0.0 | Mode: Ground Truth Reset\n",
      "[2025-08-14 22:59:06] Step     2/12000 | Pos:  8001 | MAPE: 0.0215 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:59:07] Step     3/12000 | Pos:  8002 | MAPE: 0.0233 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:59:07] Step     4/12000 | Pos:  8003 | MAPE: 0.0263 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:59:07] Step     5/12000 | Pos:  8004 | MAPE: 0.0311 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:59:07] Step     6/12000 | Pos:  8005 | MAPE: 0.0369 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:59:07] Step     7/12000 | Pos:  8006 | MAPE: 0.0434 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:59:08] Step     8/12000 | Pos:  8007 | MAPE: 0.0507 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:59:08] Step     9/12000 | Pos:  8008 | MAPE: 0.0584 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 22:59:08] Step    10/12000 | Pos:  8009 | MAPE: 0.0666 | Flag: 0.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:00:24] Step   500/12000 | Pos:  8499 | MAPE: 0.3978 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:01:48] Step  1000/12000 | Pos:  8999 | MAPE: 0.4591 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:03:14] Step  1500/12000 | Pos:  9499 | MAPE: 0.4250 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:04:37] Step  2000/12000 | Pos:  9999 | MAPE: 0.3874 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:06:01] Step  2500/12000 | Pos: 10499 | MAPE: 0.3567 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:07:37] Step  3000/12000 | Pos: 10999 | MAPE: 0.3164 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:08:46] Step  3500/12000 | Pos: 11499 | MAPE: 0.2733 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:10:05] Step  4000/12000 | Pos: 11999 | MAPE: 0.2458 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:11:27] Step  4500/12000 | Pos: 12499 | MAPE: 0.3514 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:12:41] Step  5000/12000 | Pos: 12999 | MAPE: 0.5873 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:14:17] Step  5500/12000 | Pos: 13499 | MAPE: 0.7521 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:16:05] Step  6000/12000 | Pos: 13999 | MAPE: 0.9404 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:17:52] Step  6500/12000 | Pos: 14499 | MAPE: 1.1384 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:19:41] Step  7000/12000 | Pos: 14999 | MAPE: 3.0174 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:21:16] Step  7500/12000 | Pos: 15499 | MAPE: 3.6160 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:22:43] Step  8000/12000 | Pos: 15999 | MAPE: 3.6843 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:24:12] Step  8500/12000 | Pos: 16499 | MAPE: 3.7758 | Flag: 1.0 | Mode: Auto-Regressive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-14 23:25:14] Step  9000/12000 | Pos: 16999 | MAPE: 3.9342 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:26:11] Step  9500/12000 | Pos: 17499 | MAPE: 4.1808 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:27:07] Step 10000/12000 | Pos: 17999 | MAPE: 4.4207 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:28:03] Step 10500/12000 | Pos: 18499 | MAPE: 4.6238 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:29:11] Step 11000/12000 | Pos: 18999 | MAPE: 4.7955 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:30:47] Step 11500/12000 | Pos: 19499 | MAPE: 5.0184 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "[2025-08-14 23:32:13] Step 12000/12000 | Pos: 19999 | MAPE: 5.2475 | Flag: 1.0 | Mode: Auto-Regressive\n",
      "\n",
      "[2025-08-14 23:32:14] ‚úÖ Horizon 100 completed:\n",
      "   Average MAPE: 5.2475\n",
      "   Valid predictions: 12000/12000\n",
      "\n",
      "================================================================================\n",
      "[2025-08-14 23:32:14] üéâ CORRECTED INFERENCE COMPLETED\n",
      "================================================================================\n",
      "Horizon   50: 5.5260 MAPE\n",
      "Horizon  100: 5.2475 MAPE\n",
      "\n",
      "[2025-08-14 23:32:14] üí° Key corrections made:\n",
      "   ‚úÖ Start prediction from end of training data (sample 8000)\n",
      "   ‚úÖ Use correct binary flags from proper temporal positions\n",
      "   ‚úÖ Handle ground truth availability correctly\n",
      "   ‚úÖ Maintain proper sequence continuity\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def timestamp(): \n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# ============================================================================\n",
    "# CORRECTED PARAMETERS AND DATA HANDLING\n",
    "# ============================================================================\n",
    "\n",
    "# Key parameters\n",
    "TRAINING_SAMPLES = 8000      # Samples used for training\n",
    "TOTAL_SAMPLES = 20000        # Total samples in dataset\n",
    "seq_length = 20\n",
    "steps_to_pred = 12000        # How many steps to predict beyond training\n",
    "batch_size = 32\n",
    "molecules = 2\n",
    "species = '2_22'\n",
    "horizons = np.array([50, 100])\n",
    "\n",
    "print(f\"[{timestamp()}] üîß CORRECTED INFERENCE SETUP:\")\n",
    "print(f\"   Training used: {TRAINING_SAMPLES} samples\")\n",
    "print(f\"   Total dataset: {TOTAL_SAMPLES} samples\") \n",
    "print(f\"   Predicting: {steps_to_pred} steps beyond training\")\n",
    "print(f\"   Available for prediction: {TOTAL_SAMPLES - TRAINING_SAMPLES} = {TOTAL_SAMPLES - TRAINING_SAMPLES} samples\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD AND VERIFY DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Load the FULL dataset\n",
    "full_data = np.load(f'{species}_data.npy')\n",
    "print(f\"[{timestamp()}] üìÅ Loaded full dataset: {full_data.shape}\")\n",
    "\n",
    "# Verify we have enough data\n",
    "if TOTAL_SAMPLES > len(full_data):\n",
    "    print(f\"‚ùå Error: Dataset only has {len(full_data)} samples, need {TOTAL_SAMPLES}\")\n",
    "    exit(1)\n",
    "\n",
    "if TRAINING_SAMPLES + steps_to_pred > TOTAL_SAMPLES:\n",
    "    print(f\"‚ùå Error: Training ({TRAINING_SAMPLES}) + prediction ({steps_to_pred}) > total ({TOTAL_SAMPLES})\")\n",
    "    exit(1)\n",
    "\n",
    "# Use only the specified amount\n",
    "full_data = full_data[:TOTAL_SAMPLES, :]\n",
    "print(f\"[{timestamp()}] üìÅ Using dataset: {full_data.shape}\")\n",
    "\n",
    "# Split data correctly\n",
    "training_data = full_data[:TRAINING_SAMPLES, :]          # First 8,000 for training context\n",
    "prediction_data = full_data[TRAINING_SAMPLES:, :]        # Remaining for prediction/validation\n",
    "\n",
    "print(f\"[{timestamp()}] üîÑ Data split:\")\n",
    "print(f\"   Training context: {training_data.shape} (samples 0 to {TRAINING_SAMPLES-1})\")\n",
    "print(f\"   Prediction range: {prediction_data.shape} (samples {TRAINING_SAMPLES} to {TOTAL_SAMPLES-1})\")\n",
    "\n",
    "# Verify binary flags in full dataset\n",
    "binary_flags = full_data[:, 6]\n",
    "ones_indices = np.where(binary_flags == 1)[0]\n",
    "print(f\"[{timestamp()}] ‚ö° Binary flag analysis:\")\n",
    "print(f\"   Total '1' flags: {len(ones_indices)}\")\n",
    "print(f\"   Pattern check - first 10 indices: {ones_indices[:10]}\")\n",
    "print(f\"   Expected pattern: every 100 steps starting from some offset\")\n",
    "\n",
    "# Check if pattern is every 100 steps\n",
    "if len(ones_indices) > 1:\n",
    "    differences = np.diff(ones_indices)\n",
    "    print(f\"   Intervals between flags: {differences[:10]} (should be mostly 100)\")\n",
    "\n",
    "# ============================================================================\n",
    "# CORRECTED INFERENCE SETUP\n",
    "# ============================================================================\n",
    "\n",
    "def create_initial_sequence_from_training(training_data, seq_length):\n",
    "    \"\"\"Create initial sequence from the LAST part of training data\"\"\"\n",
    "    if len(training_data) < seq_length:\n",
    "        raise ValueError(f\"Training data too short: {len(training_data)} < {seq_length}\")\n",
    "    \n",
    "    # Take the last seq_length samples from training\n",
    "    sequence = training_data[-seq_length:, :]\n",
    "    return np.expand_dims(sequence, axis=0)\n",
    "\n",
    "def get_correct_binary_flag(full_data, training_samples, prediction_step):\n",
    "    \"\"\"Get the correct binary flag for a given prediction step\"\"\"\n",
    "    # The actual position in the full dataset\n",
    "    actual_position = training_samples + prediction_step\n",
    "    \n",
    "    if actual_position >= len(full_data):\n",
    "        # If we've gone beyond available data, extrapolate the pattern\n",
    "        # Assuming the pattern repeats every 100 steps\n",
    "        ones_indices = np.where(full_data[:, 6] == 1)[0]\n",
    "        if len(ones_indices) > 0:\n",
    "            # Find the pattern\n",
    "            pattern_start = ones_indices[0] % 100\n",
    "            flag_value = 1 if (actual_position % 100) == pattern_start else 0\n",
    "            print(f\"   ‚ö° Extrapolating flag for position {actual_position}: {flag_value}\")\n",
    "            return flag_value\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    return full_data[actual_position, 6]\n",
    "\n",
    "def get_ground_truth_if_available(full_data, training_samples, prediction_step):\n",
    "    \"\"\"Get ground truth if available, otherwise return None\"\"\"\n",
    "    actual_position = training_samples + prediction_step\n",
    "    \n",
    "    if actual_position < len(full_data):\n",
    "        return full_data[actual_position, :6].reshape(1, -1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ============================================================================\n",
    "# CORRECTED INFERENCE LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n[{timestamp()}] üöÄ Starting corrected inference...\")\n",
    "\n",
    "# Load model\n",
    "model = load_model(f'transformer_model_384_{species}.h5')\n",
    "print(f\"[{timestamp()}] ‚úÖ Model loaded: {model.input_shape} ‚Üí {model.output_shape}\")\n",
    "\n",
    "# Track performance summary\n",
    "summary = {}\n",
    "\n",
    "for j, horizon in enumerate(horizons):\n",
    "    horizon_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\n[{timestamp()}] üéØ Starting horizon {horizon}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Initialize tracking\n",
    "    performance = np.zeros((steps_to_pred, 1))\n",
    "    predictions = np.zeros((steps_to_pred, 2 * molecules * 3))\n",
    "    \n",
    "    # Start with the last sequence from training data\n",
    "    current_sequence = create_initial_sequence_from_training(training_data, seq_length)\n",
    "    print(f\"[{timestamp()}] üîÑ Initial sequence shape: {current_sequence.shape}\")\n",
    "    print(f\"   Starting from training samples {TRAINING_SAMPLES-seq_length} to {TRAINING_SAMPLES-1}\")\n",
    "    \n",
    "    using_ground_truth = True\n",
    "    \n",
    "    for i in range(steps_to_pred):\n",
    "        # Make prediction\n",
    "        prediction = model.predict(current_sequence, steps=1, verbose=0)\n",
    "        \n",
    "        # Get ground truth if available\n",
    "        ground_truth = get_ground_truth_if_available(full_data, TRAINING_SAMPLES, i)\n",
    "        \n",
    "        # Calculate performance if ground truth available\n",
    "        if ground_truth is not None:\n",
    "            error = tf.metrics.mean_absolute_percentage_error(ground_truth, prediction)\n",
    "            performance[i, 0] = error.numpy()\n",
    "            predictions[i, :molecules*3] = prediction.flatten()\n",
    "            predictions[i, molecules*3:] = ground_truth.flatten()\n",
    "        else:\n",
    "            performance[i, 0] = -1  # No ground truth available\n",
    "            predictions[i, :molecules*3] = prediction.flatten()\n",
    "            if i == 0:\n",
    "                print(f\"[{timestamp()}] ‚ö†Ô∏è  No more ground truth available from step {i}\")\n",
    "        \n",
    "        # Get the correct binary flag\n",
    "        binary_flag = get_correct_binary_flag(full_data, TRAINING_SAMPLES, i)\n",
    "        \n",
    "        # Create full prediction (coordinates + binary flag)\n",
    "        full_prediction = np.zeros((1, 7))\n",
    "        full_prediction[0, :6] = prediction.flatten()\n",
    "        full_prediction[0, 6] = binary_flag\n",
    "        \n",
    "        # Update sequence based on horizon strategy\n",
    "        if horizon == 1:\n",
    "            # Always use ground truth if available, otherwise use prediction\n",
    "            if ground_truth is not None:\n",
    "                next_step = np.zeros((1, 7))\n",
    "                next_step[0, :6] = ground_truth.flatten()\n",
    "                next_step[0, 6] = binary_flag\n",
    "                current_sequence = np.concatenate([current_sequence[:, 1:, :], \n",
    "                                                 next_step.reshape(1, 1, -1)], axis=1)\n",
    "                mode = \"Ground Truth\"\n",
    "            else:\n",
    "                current_sequence = np.concatenate([current_sequence[:, 1:, :], \n",
    "                                                 full_prediction.reshape(1, 1, -1)], axis=1)\n",
    "                mode = \"Auto-Regressive\"\n",
    "                using_ground_truth = False\n",
    "                \n",
    "        else:\n",
    "            # Multi-step horizon strategy\n",
    "            if i % horizon == 0 and ground_truth is not None:\n",
    "                # Reset with ground truth every 'horizon' steps\n",
    "                reset_start = max(0, TRAINING_SAMPLES + i - seq_length + 1)\n",
    "                reset_end = TRAINING_SAMPLES + i + 1\n",
    "                \n",
    "                if reset_end <= len(full_data):\n",
    "                    current_sequence = full_data[reset_start:reset_end, :].reshape(1, seq_length, -1)\n",
    "                    mode = \"Ground Truth Reset\"\n",
    "                    using_ground_truth = True\n",
    "                else:\n",
    "                    # Continue with prediction\n",
    "                    current_sequence = np.concatenate([current_sequence[:, 1:, :], \n",
    "                                                     full_prediction.reshape(1, 1, -1)], axis=1)\n",
    "                    mode = \"Auto-Regressive\"\n",
    "                    using_ground_truth = False\n",
    "            else:\n",
    "                # Continue with previous prediction\n",
    "                current_sequence = np.concatenate([current_sequence[:, 1:, :], \n",
    "                                                 full_prediction.reshape(1, 1, -1)], axis=1)\n",
    "                mode = \"Auto-Regressive\"\n",
    "                using_ground_truth = False\n",
    "        \n",
    "        # Progress reporting\n",
    "        if (i + 1) % 500 == 0 or i < 10:\n",
    "            actual_pos = TRAINING_SAMPLES + i\n",
    "            valid_perf = performance[:i+1][performance[:i+1, 0] >= 0, 0]\n",
    "            \n",
    "            if len(valid_perf) > 0:\n",
    "                avg_mape = np.mean(valid_perf)\n",
    "                print(f\"[{timestamp()}] Step {i+1:5d}/{steps_to_pred} | Pos: {actual_pos:5d} | \"\n",
    "                      f\"MAPE: {avg_mape:.4f} | Flag: {binary_flag} | Mode: {mode}\")\n",
    "            else:\n",
    "                print(f\"[{timestamp()}] Step {i+1:5d}/{steps_to_pred} | Pos: {actual_pos:5d} | \"\n",
    "                      f\"No valid MAPE | Flag: {binary_flag} | Mode: {mode}\")\n",
    "    \n",
    "    # Save results\n",
    "    perf_file = f\"corrected_performance_{species}_horizon_{horizon}.csv\"\n",
    "    pred_file = f\"corrected_predictions_{species}_horizon_{horizon}.csv\"\n",
    "    np.savetxt(perf_file, performance, delimiter=\",\")\n",
    "    np.savetxt(pred_file, predictions, delimiter=\",\")\n",
    "    \n",
    "    # Calculate final statistics\n",
    "    valid_perf = performance[performance[:, 0] >= 0, 0]\n",
    "    if len(valid_perf) > 0:\n",
    "        avg_perf = np.mean(valid_perf)\n",
    "        print(f\"\\n[{timestamp()}] ‚úÖ Horizon {horizon} completed:\")\n",
    "        print(f\"   Average MAPE: {avg_perf:.4f}\")\n",
    "        print(f\"   Valid predictions: {len(valid_perf)}/{steps_to_pred}\")\n",
    "        summary[horizon] = avg_perf\n",
    "    else:\n",
    "        print(f\"\\n[{timestamp()}] ‚ùå Horizon {horizon}: No valid predictions\")\n",
    "        summary[horizon] = None\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"[{timestamp()}] üéâ CORRECTED INFERENCE COMPLETED\")\n",
    "print(f\"{'='*80}\")\n",
    "for h, v in summary.items():\n",
    "    if v is not None:\n",
    "        print(f\"Horizon {h:4d}: {v:.4f} MAPE\")\n",
    "    else:\n",
    "        print(f\"Horizon {h:4d}: No valid data\")\n",
    "\n",
    "print(f\"\\n[{timestamp()}] üí° Key corrections made:\")\n",
    "print(f\"   ‚úÖ Start prediction from end of training data (sample {TRAINING_SAMPLES})\")\n",
    "print(f\"   ‚úÖ Use correct binary flags from proper temporal positions\")\n",
    "print(f\"   ‚úÖ Handle ground truth availability correctly\")\n",
    "print(f\"   ‚úÖ Maintain proper sequence continuity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb28a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
